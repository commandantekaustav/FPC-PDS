{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 51: The Machine Learning Workflow in Python\n",
    "\n",
    "**Unit 5: Basics of Predictive Analytics**\n",
    "**Hour: 51**\n",
    "**Mode: Practical Lab**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Objective\n",
    "\n",
    "This lab introduces the standard workflow for preparing data for machine learning in Python using the **Scikit-learn** library. Before we can train a model, we must:\n",
    "1.  Separate our data into features (X) and the target (y).\n",
    "2.  Convert categorical features into a numerical format.\n",
    "3.  Split our data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup\n",
    "\n",
    "We will use our clean Telco dataset. For this lab, we'll focus on a smaller subset of columns for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Let's use a smaller set of features for this example\n",
    "df_subset = df[['tenure', 'MonthlyCharges', 'Contract', 'Churn']].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "# Simple cleaning for this subset\n",
    "df_subset.dropna(inplace=True)\n",
    "df_subset = df_subset[df_subset['TotalCharges'] != ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Step 1: Separate Features (X) and Target (y)\n",
    "\n",
    "*   The **target (y)** is the single column we are trying to predict. In our case, this is `Churn`.\n",
    "*   The **features (X)** are all the other columns we will use to make the prediction.\n",
    "\n",
    "By convention, `X` is capitalized because it's a matrix (a DataFrame), and `y` is lowercase because it's a vector (a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_subset.drop('Churn', axis=1)\n",
    "y = df_subset['Churn']\n",
    "\n",
    "print(\"--- Features (X) ---\")\n",
    "print(X.head())\n",
    "print(\"\\n--- Target (y) ---\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Step 2: Convert Categorical Features to Numbers\n",
    "\n",
    "Machine learning models are mathematical, so they can't understand text values like 'Month-to-month'. We need to convert them into numbers. The most common method is **One-Hot Encoding**.\n",
    "\n",
    "One-Hot Encoding takes a categorical column and creates a new binary (0 or 1) column for each category. Pandas has a simple function for this called `pd.get_dummies()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=['Contract'], drop_first=True)\n",
    "# drop_first=True is used to avoid multicollinearity, a statistical issue.\n",
    "\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** The `Contract` column has been replaced by two new columns. For a customer with a 'One year' contract, the `Contract_One year` column is 1 and `Contract_Two year` is 0. If both are 0, it implies the contract was 'Month-to-month'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Step 3: Split Data into Training and Testing Sets\n",
    "\n",
    "This is a crucial step. We need to hold back some of our data to evaluate our model's performance on data it has **never seen before**.\n",
    "\n",
    "*   **Training Set:** The data we use to teach the model (usually 70-80% of the data).\n",
    "*   **Testing Set:** The data we use to test how well the model learned (usually 20-30% of the data).\n",
    "\n",
    "Scikit-learn provides a handy function, `train_test_split`, to do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size=0.2 means we'll hold back 20% of the data for testing.\n",
    "# random_state=42 ensures that we get the same split every time we run the code, for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "In this session, you learned the essential preprocessing steps for any supervised machine learning project:\n",
    "1.  **Separate** your data into features `X` and a target `y`.\n",
    "2.  **Encode** categorical text data into a numerical format using `pd.get_dummies()`.\n",
    "3.  **Split** your data into training and testing sets using `train_test_split` to ensure a fair evaluation.\n",
    "\n",
    "Our data is now fully prepared. We are ready to train our first model in Python.\n",
    "\n",
    "**Next Session:** We will build a Linear Regression model in Python to predict `TotalCharges`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}