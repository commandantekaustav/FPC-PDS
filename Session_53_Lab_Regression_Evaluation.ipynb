{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 53: Regression Model Evaluation\n",
    "\n",
    "**Unit 5: Basics of Predictive Analytics**\n",
    "**Hour: 53**\n",
    "**Mode: Practical Lab**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Objective\n",
    "\n",
    "This lab focuses on the crucial final step of the modeling process: **evaluation**. We need to quantify how well our Linear Regression model is performing. We will learn two of the most common metrics for regression tasks:\n",
    "1.  **R-squared (R²)**: The proportion of variance explained by the model.\n",
    "2.  **Root Mean Squared Error (RMSE)**: The average prediction error in the original units of the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup\n",
    "\n",
    "Let's recreate our model and predictions from the previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load and clean data\n",
    "url = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Prep data and train model\n",
    "X = df[['tenure', 'MonthlyCharges']]\n",
    "y = df['TotalCharges']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Metric 1: R-squared (R²)\n",
    "\n",
    "This metric is the same `R Square` we saw in the Excel output. It measures how much of the variability in our target variable (`TotalCharges`) is captured by our model.\n",
    "\n",
    "*   **Range:** 0 to 1 (or 0% to 100%).\n",
    "*   **Interpretation:** A higher R² is generally better. An R² of 0.75 means your model explains 75% of the variance in the target.\n",
    "\n",
    "Scikit-learn provides the `r2_score` function. We compare the true values (`y_test`) with our model's predictions (`y_pred`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Our model explains approximately **90.4%** of the variance in `TotalCharges` on the unseen test data. This is a very strong score and indicates our model has a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Metric 2: Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)\n",
    "\n",
    "While R² tells us about the proportion of variance explained, it doesn't tell us about the magnitude of the prediction error in the original units.\n",
    "\n",
    "*   **Mean Squared Error (MSE):** This is the average of the squared differences between the predicted and actual values. The squaring punishes larger errors more heavily. The units are squared (e.g., dollars squared), which is hard to interpret.\n",
    "*   **Root Mean Squared Error (RMSE):** This is simply the square root of the MSE. Its great advantage is that the error is now in the **same units as the target variable** (e.g., dollars). This makes it much more intuitive.\n",
    "\n",
    "**Interpretation:** The RMSE can be thought of as the \"typical\" or \"average\" error of your model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "\n",
    "# Calculate RMSE by taking the square root\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** An RMSE of `$713.84` means that on average, our model's prediction for a customer's `TotalCharges` is off by about $713.84. Whether this is \"good\" or \"bad\" depends on the business context. Given that total charges can be over $8000, this might be an acceptable level of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusion\n",
    "\n",
    "In this lab, you learned how to evaluate the performance of your regression model:\n",
    "1.  **R-squared (R²)** tells you the *proportion of variance explained* (a measure of fit).\n",
    "2.  **Root Mean Squared Error (RMSE)** tells you the *typical prediction error* in the original units of your target.\n",
    "\n",
    "Using these two metrics together gives you a comprehensive understanding of your model's performance. Our model for predicting `TotalCharges` is quite strong, with a high R² and a reasonable RMSE.\n",
    "\n",
    "**Next Session:** We will switch gears from regression to classification and build our first model to predict the `Churn` outcome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}