{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 55: Classification Evaluation (Accuracy)\n",
    "\n",
    "**Unit 5: Basics of Predictive Analytics**\n",
    "**Hour: 55**\n",
    "**Mode: Practical Lab**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Objective\n",
    "\n",
    "This lab introduces the most intuitive metric for classification tasks: **Accuracy**. We will learn what it represents, how to calculate it, and discuss its limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup\n",
    "\n",
    "Let's recreate our Logistic Regression model and predictions from the previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and prep data\n",
    "url = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url)\n",
    "df_subset = df[['tenure', 'MonthlyCharges', 'Contract', 'Churn']].copy()\n",
    "df_subset.dropna(inplace=True)\n",
    "\n",
    "# Prep data and train model\n",
    "X = df_subset.drop('Churn', axis=1)\n",
    "y = df_subset['Churn']\n",
    "X_encoded = pd.get_dummies(X, columns=['Contract'], drop_first=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model and make predictions\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Understanding Accuracy\n",
    "\n",
    "**Definition:** Accuracy is the proportion of predictions that the model got correct.\n",
    "\n",
    "**Formula:** `Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)`\n",
    "\n",
    "It's simple to understand and is a good starting point for most classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculating Accuracy\n",
    "\n",
    "Scikit-learn provides the `accuracy_score` function. We compare the true labels (`y_test`) with our model's predictions (`y_pred`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {acc:.4f}\")\n",
    "print(f\"Model Accuracy as a percentage: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Our model correctly predicts whether a customer will churn or not approximately **79.53%** of the time on the unseen test data. This is a respectable first result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The Limitation of Accuracy: Imbalanced Datasets\n",
    "\n",
    "Accuracy can be misleading when you have an **imbalanced dataset**. An imbalanced dataset is one where one class is much more frequent than the other.\n",
    "\n",
    "Let's check the balance of our target variable, `Churn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Problem:** In our test set, about 73% of customers did **not** churn. This means that a lazy, \"dumb\" model that **always** predicts \"No\" for churn would still achieve an accuracy of 73%!\n",
    "\n",
    "Our model's accuracy is `79.53%`, which is better than the lazy model's `73%`, so we know it has learned something useful. However, this illustrates why accuracy alone isn't enough.\n",
    "\n",
    "**Analogy:** Imagine you have a test to detect a rare disease that only affects 1 in 1000 people. A model that always predicts \"No Disease\" would be 99.9% accurate, but it would be completely useless because it would never find the one person who is actually sick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "In this lab, you learned:\n",
    "1.  **Accuracy** is the percentage of correct predictions.\n",
    "2.  How to calculate it using Scikit-learn's `accuracy_score`.\n",
    "3.  The critical limitation of accuracy, especially on **imbalanced datasets**, where it can be a misleading metric.\n",
    "\n",
    "Because accuracy can be misleading, data scientists need more nuanced tools to evaluate classification models.\n",
    "\n",
    "**Next Session:** We will introduce the **Confusion Matrix**, a powerful tool that breaks down a model's performance and gives us a much deeper understanding of its strengths and weaknesses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}